<!DOCTYPE html>
<html lang="en">
<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" type="text/css" href="https://trimbljk.github.io/theme/css/custom.css">
	<link rel="stylesheet" type="text/css" href="https://trimbljk.github.io/theme/css/articles.css">
	<link rel="shortcut icon" type="image/svg" href="https://trimbljk.github.io/theme/images/libertyflame.svg">
	<title>building-first-infrastructure</title>

</head>
<body>
	<header class="header">			
		<div class="title-fav">
			<h1 id=top-title>Just Another Data Science Blog...</h1>
			<ul id="social-favi">
				<li class="favi-list">
					<a href="https://www.github.com/Trimbljk"><img class="faviconimg" src="https://trimbljk.github.io/theme/images/github-logo.svg" height="45" width="45"></a></li>
				<li class="favi-list">
			<a href="https://www.linkedin.com/in/jake-trimble/"><img class="faviconimg" src="https://trimbljk.github.io/theme/images/linkedin.svg" height="45" width="45"></a></li>
				<li class="favi-list">
			<a href="https://www.twitter.com/JakeTrimble11/"><img class="faviconimg" src="https://trimbljk.github.io/theme/images/twitter.svg" height="45" width="45"></a></li>
			</ul>
		</div> 
		<nav>
			<a href="https://trimbljk.github.io" class="nav-links">Home</a>
			<a href="https://trimbljk.github.io" class="nav-links">About</a>
			<a href="https://trimbljk.github.io/data-science.html" class="nav-links">Data Science</a>
			<a href="https://trimbljk.github.io/programming.html" class="nav-links">Programming</a>
			<a href="https://trimbljk.github.io/musings.html" class="nav-links">Musings</a>
			<a href="https://trimbljk.github.io/archives.html" class="nav-links">Archives</a>
            	</nav>
        </header>
<main class="main-article-content">
	<div class="article-title">
		Building Infrastructure to Support USDA NASS Data
		<div class="article-date">
			<time class="published" datetime="2020-11-23T00:00:00-05:00">
				2020-November-23
			</time>
		</div>
	</div>
	<div class="article-content">
	<p>Before we start gathering crop data to analyze, we should build some serverless infrastructure that can handle large datasets. Fortunately, most major tech companies (Google, Amazon, Microsoft) have wonderful cloud-platforms that allow customers to build any type of infrastructure to support any application.</p>
<p>We're going to use Amazon Web Service (AWS) to build the infrasture we need to manage the data we collect. If you haven't created AWS credentials yet, go ahead and follow the intructions <a href="https://portal.aws.amazon.com/billing/signup#/start" class="inlinelink">here</a>. Once you're set up, navigate to the <a href="https://aws.amazon.com" class="inlinelink">AWS Homepage</a> and hover over the <em>Products</em> tab, you'll see a variety of solutions from which to choose. For this project, we'll be using <a href="https://aws.amazon.com/s3" class="inlinelink">AWS Simple Storage Service</a> or S3, <a href="https://aws.amazon.com/glue/?nc2=h_ql_prod_an_glu&whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc" class="inlinelink">AWS Glue</a>, and <a href="https://aws.amazon.com/athena/?nc2=h_ql_prod_an_ath&whats-new-cards.sort-by=item.additionalFields.postDateTime&whats-new-cards.sort-order=desc" class="inlinelink">AWS Athena</a>. We'll be using S3 to store the files we request from the USDA NASS API. We'll use Glue to crawl our S3 bucket and then use Athena to query that information. To set it all up, we'll use <a href="https://docs.aws.amazon.com/serverless-application-model/?id=docs_gateway" class="inlinelink">AWS Serverless Application Management (SAM)</a> and <a href="https://aws.amazon.com/cloudformation/?nc2=h_ql_prod_mg_cfA" class="inlinelink">AWS Cloudformation</a>.
Let's get started.</p>
<p>To build our infrastructure, we'll be using a cloudformation template. This template can be constructed using JSON or YAML format. The template specifies infrastructure needs as code allowing portability. We'll specify our format in YAML (I find it easier to read). Because we're using AWS Serverless Application Management (SAM), instead of just cloudformation, the template will requires the following two headers:
<pre class="setpre">
<code class="aws-infrastructure-code"><span class="infra-variable">AWSTemplateFormatVersion</span><span class="colon">:</span><span class="infra-string-value"> '2010-09-09'</span>
<span class="infra-variable">Transform</span><span class="colon">:</span><span class="infra-noq-string-value"> AWS::Serverless-2016-10-31</span></code>
</pre>
Next, we'll specify some resources. We need an S3 bucket to which we'll eventually upload our data, a crawler to pull information from that S3 bucket and a database to place the data once it's been crawled. All resources are grouped under the <strong>Resources</strong> header. First we'll draft our bucket:
<pre class="setpre">
<code class="aws-infrastructure-code"><span class="infra-variable">Resources</span><span class="colon">:</span>
  <span class="infra-variable">OutputBucket</span><span class="colon">:</span>
    <span class="infra-variable">Type</span><span class="colon">:</span><span class="infra-noq-string-value"> AWS::S3::Bucket</span>
    <span class="infra-variable">Properties</span><span class="colon">:</span>
      <span class="infra-variable">BucketName</span><span class="colon">:</span><span class="infra-string-value"> 'jkt-usda-api-crop-data'</span>
      <span class="infra-variable">PublicAccessBlockConfiguration</span><span class="colon">:</span>
        <span class="infra-variable">BlockPublicAcls</span><span class="colon">:</span><span class="infra-noq-string-value"> True</span>
        <span class="infra-variable">BlockPublicPolicy</span><span class="colon">:</span><span class="infra-noq-string-value"> True</span>
        <span class="infra-variable">IgnorePublicAcls</span><span class="colon">:</span><span class="infra-noq-string-value"> True</span>
        <span class="infra-variable">RestrictPublicBuckets</span><span class="colon">:</span><span class="infra-noq-string-value"> True</span></code>
</pre>
We first assign a name to the resource with <strong>OutputBucket</strong> and tell AWS what kind of resource it is using AWS's inherent data convention <strong>AWS::S3::Bucket</strong>. We then describe what the bucket "looks like" under the <strong>Properties</strong> variable. The bucket name must be universal in the S3 namespace and I set all my access restrictions to <strong>True</strong> because I want my bucket to be private. Even though private is the default setting on S3 it's good practice to specify it explictly by blocking any public access.</p>
<p>Next, we'll specify our database resource. This database will hold all the information we'll be supplying to S3.
<pre class="setpre">
<code class="aws-infrastructure-code">  <span class="infra-variable">Cropdatabase</span><span class="colon">:</span>
    <span class="infra-variable">Type</span><span class="colon">:</span><span class="infra-noq-string-value"> AWS::Glue::Database</span>
    <span class="infra-variable">Properties</span><span class="colon">:</span>
      <span class="infra-variable">CatalogId</span><span class="colon">:</span><span class="aws-intrinsic-func"> !Ref</span><span class="infra-noq-string-value"> AWS::AccountId </span>
      <span class="infra-variable">DatabaseInput</span><span class="colon">:</span>
        <span class="infra-variable">Name</span><span class="colon">:</span><span class="infra-string-value"> "crop_data"</span></code>
</pre></p>
<pre class="setpre">
<code class="aws-infrastructure-code">  <span class="infra-variable">Crawler</span><span class="colon">:</span>
    <span class="infra-variable">Type</span><span class="colon">:</span><span class="infra-noq-string-value"> AWS::Glue::Crawler</span>
    <span class="infra-variable">Properties</span><span class="colon">:</span>
      <span class="infra-variable">Name</span><span class="colon">:</span><span class="infra-string-value"> 'crop-data-crawler' </span>
      <span class="infra-variable">SchemaChangePolicy</span><span class="colon">:</span>
        <span class="infra-variable">UpdateBehavior</span><span class="colon">:</span><span class="infra-noq-string-value"> UPDATE_IN_DATABASE</span>
        <span class="infra-variable">DeleteBehavior</span><span class="colon">:</span><span class="infra-noq-string-value"> DELETE_FROM_DATABASE</span>
      <span class="infra-variable">TablePrefix</span><span class="colon">:</span><span class="infra-noq-string-value"> usda_</span>
      <span class="infra-variable">DatabaseName</span><span class="colon">:</span><span class="aws-intrinsic-func"> !Ref</span><span class="infra-noq-string-value"> CropDatabase</span>
      <span class="infra-variable">Targets</span><span class="colon">:</span>
        <span class="infra-variable">S3Targets</span><span class="colon">:</span>
          <span class="infra-list-dash">-</span><span class="infra-variable"> Path</span><span class="colon">:</span><span class="aws-intrinsic-func"> !Sub</span>
            <span class="infra-list-dash">-</span><span class="infra-string-value"> 's3://${Bucket}/crop-data'</span>
			<span class="infra-list-dash">-</span><span class="colon"> { </span><span class="infra-string-value">Bucket</span><span class="colon">:</span><span class="infra-noq-string-value"> !Ref OutputBucket</span><span class="colon"> }</span>
      <span class="infra-variable">Schedule</span><span class="colon">:</span>
        <span class="infra-variable">ScheduleExpression</span><span class="colon">:</span><span class="infra-string-value"> 'cron(0 0 ? * MON *)' </span>
      <span class="infra-variable">Role</span><span class="colon">:</span><span class="infra-noq-string-value"> AWSglueServiceRole</span></code>
</pre>

<p>Once we have our template prepared, we can use the AWS SAM CLI to deploy our infrastructure.</p>
<p>INSERT PICTURE OF THE SAM DEPLOY COMMANDS</p>
<p>You should receive a success notification at the CLI. If not you'll have to determine what the are was and fix it accordingly. Once our infrastructure is deployed, we can shift back to thinking about what data we want to collect from the USDA NASS website. </p>
	</div>
</main>
	<footer class="footer">
		<div>Copyright Â© 2021 Jake Trimble</div>
		<div class="pelican-info">
		<address class="address">
			Proudly powered by Pelican
		</address><!-- /#about -->
		<div>Theme by <a href="https://github.com/Trimbljk">@trimbljk</a></div>
		</div>
	</footer>
</body>
</html>
