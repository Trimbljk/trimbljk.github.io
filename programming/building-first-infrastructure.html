<!DOCTYPE html>
<html lang="en">
<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" type="text/css" href="https://trimbljk.github.io/theme/css/custom.css">
	<link rel="stylesheet" type="text/css" href="https://trimbljk.github.io/theme/css/articles.css">
	<title>building-first-infrastructure</title>

</head>
<body>
	<header class="header">			
		<div class="title-fav">
			<h1 id=top-title>Just Another Data Science Blog...</h1>
			<ul id="social-favi">
				<li class="favi-list">
					<a href="https://www.github.com/Trimbljk"><img src="https://trimbljk.github.io/theme/images/github-logo.svg" height="45" width="45"></a></li>
				<li class="favi-list">
			<a href="https://www.linkedin.com/in/jake-trimble/"><img src="https://trimbljk.github.io/theme/images/linkedin.svg" height="45" width="45"></a></li>
				<li class="favi-list">
			<a href="https://www.twitter.com/JakeTrimble11/"><img src="https://trimbljk.github.io/theme/images/twitter.svg" height="45" width="45"></a></li>
			</ul>
		</div> 
		<nav>
			<a href="https://trimbljk.github.io" class="nav-links">Home</a>
			<a href="https://trimbljk.github.io" class="nav-links">About</a>
			<a href="https://trimbljk.github.io/data-science.html" class="nav-links">Data Science</a>
			<a href="https://trimbljk.github.io/programming.html" class="nav-links">Programming</a>
			<a href="https://trimbljk.github.io/musings.html" class="nav-links">Musings</a>
			<a href="https://trimbljk.github.io/archives.html" class="nav-links">Archives</a>
            	</nav>
        </header>
<main class="main-article-content">
	<div class="article-title">
		Building Infrastructure to Support USDA NASS Data
		<div class="article-date">
			<time class="published" datetime="2020-11-23T00:00:00-05:00">
				2020-November-23
			</time>
		</div>
	</div>
	<div class="article-content">
	<p>Before we start gathering data we should build some infrastructure that can handle large amounts and doesn't require our own server. Fortunately, most major tech companies (Google, Amazon, Microsoft) have wonderful cloud-platforms that abstract the hardware allowing customers to build any type of infrastructure to support any application.</p>
<p>We're going to use Amazon Web Service (AWS) to build the infrasture we need to manage the data we collect. If you haven't created AWS credentials yet, go ahead and follow the intructions <a href="https://portal.aws.amazon.com/billing/signup#/start">here</a>. Once you're set up, navigate to the <a href="https://aws.amazon.com">AWS Homepage</a> and hover over the <code>Products</code> tab, you'll see a variety of solutions from which to choose. For this project, we'll be using <a href="https://aws.amazon.com/s3">AWS Simple Storage Service</a> or S3, <a href="https://aws.amazon.com/glue/?nc2=h_ql_prod_an_glu&amp;whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;whats-new-cards.sort-order=desc">AWS Glue</a>, and <a href="https://aws.amazon.com/athena/?nc2=h_ql_prod_an_ath&amp;whats-new-cards.sort-by=item.additionalFields.postDateTime&amp;whats-new-cards.sort-order=desc">AWS Athena</a>. We'll be using S3 to store the files we request from the USDA NASS API. We'll use Glue to crawl our S3 bucket and then use Athena to query that information. To set it all up, we'll use <a href="https://docs.aws.amazon.com/serverless-application-model/?id=docs_gateway">AWS Serverless Application Management (SAM)</a> and <a href="https://aws.amazon.com/cloudformation/?nc2=h_ql_prod_mg_cfA">AWS Cloudformation</a>. </p>
<p>Let's get started.</p>
<p>To build our infrastructure, we'll be using a cloudformation template. This template can except JSON or YAML format. It's used to specify any infrastructure needs. We'll specify our format as a YAML (I find it easier to read). AWS requires two headers in our format:</p>
<p>INSERT FORMAT INFO HERE</p>
<p>Next, we'll specify some resources. We need an S3 bucket to which we upload our data, a crawler to pull information from the s3 bucket and a database to place the data once it's been crawled. Finally we're going to add another bucket for capturing queries from AWS Athena. This is require... (INSERT WHY HERE) Here is my template file from which I'll build the AWS infrastructure:</p>
<p>INSERT PICTURE OF TEMPLATE FILE HERE</p>
<p>Each resource has information describing various attributes. For example, we give the bucket a name and specify who has access to data in the bucket. Under the <code>Crawler</code> resource, we specify the bucket we want to crawl, shema change behaviors when adding or deleting information from the bucket. </p>
<p>Once we have our template ready, we can use the AWS SAM CLI to deploy our infrastructure.</p>
<p>INSERT PICTURE OF THE SAM DEPLOY COMMANDS</p>
<p>You should receive a success notification at the CLI. If not you'll have to determine what the are was and fix it accordingly. Once our infrastructure is deployed, we can shift back to thinking about what data we want to collect from the USDA NASS website. </p>
	</div>
</main>
	<footer class="footer">
		<div>Copyright Â© 2020 Jake Trimble</div>
		<div class="pelican-info">
		<address class="address">
			Proudly powered by Pelican
		</address><!-- /#about -->
		<div>Theme by <a href="https://github.com/Trimbljk">@trimbljk</a></div>
		</div>
	</footer>
</body>
</html>